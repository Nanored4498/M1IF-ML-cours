\chapter{Introduction, apprentissage supervisé, bornes}

\myminitoc

\sect{Introduction}

\paragraph{Qu'est ce que le machine learning ?}
Le machine learning est le développement d'algorithmes qui apprennent tout seul à partir de données. On distingue deux catégorie :
\begin{itemize}
	\item L'apprentissage supervisé : qui apprend avec des données étiquetées afin de faire de la classification, de la régression ou encore de la hiérarchisation.
	\item  L'apprentissage non supervisé : qui trouve la structure d'un jeu de données afin de faire du clustering ou de la réduction de dimensions.
\end{itemize}
Les applications principales du machine learning sont alors la vision par ordinateur, la robotique, la reconnaissance vocale, le traitement du langage, etc ...

\sect{Apprentissage supervisé}

\DEF{
	Dans la suite on utilisera les notations suivantes :
	\begin{itemize}
		\item On pose $\bm{S = \{ z_i = (x_i, y_i) \}_{i = 1}^m}$ un ensemble de $\bm{m}$ exemples d'entraînement indépendants et identiquement distribués selon une une distribution inconnue $\bm{\dist}$ sur l'espace $\bm{\Z = \X \times \Y}$.
		\item Les valeurs $x_i \in \bm{\X}$ sont généralement des vecteurs de $\R^d$ dont les composantes sont appelées les \textbf{features}.
		\item Les valeurs $y_i \in \bm{\Y}$ se trouvent dans l'ensemble discret des \textbf{classes/étiquettes} (typiquement $\Y = \{ -1, +1 \}$ en classification binaire) ou dans un ensemble continue dans le cas de régressions.
		\item Finalement on cherche une \textbf{fonction cible} $\bm{f}$ tel que $\bm{\forall (x, y) \in \X \times \Y, \, y = f(x)}$.
	\end{itemize}
}

\DEF{
	Un \textbf{algorithme d'apprentissage supervisé} $\bm{L}$ prend en entrée $S$ et retourne un modèle ou une classification $\bm{h \in \Hyp}$ le plus proche possible de $f$.
}

\exe
Si on prend pour $f$ la fonction qui retourne {\color{red}$y = +1$} si $x_1^2 + x_2^2 < R^2$ et {\color{blue}$y = -1$} sinon, alors voici le résultat que l'on peut obtenir :
\begin{center}
	\begin{tikzpicture}[thick, scale=1.2]
		\draw[greenTikz, opacity=0.4] (0, 0) circle (1);
		\node[greenTikz] at (0.8, -0.9) {$f$};
		\draw[blue] (-2, 0) -- (2, 0) node[below left, black] {$x_1$};
		\draw[blue] (0, -2) -- (0, 1.8) node[above, black] {$x_2$};
		\draw[fill, red] (0.2, 0.7) circle (0.08);
		\draw[fill, red] (-0.4, -0.5) circle (0.08);
		\draw[fill, red] (0.2, -0.3) circle (0.08);
		\draw[fill, red] (-0.3, 0.3) circle (0.08);
		\draw[fill, red] (0.4, 0.2) circle (0.08);
		\draw[orange, very thick] (0.2, -1.5)
			.. controls (-0.5, -1) and (-1, -0.2) .. (-0.95, -0.05)
			.. controls (-1, 0.2) and (-0.4, 1) .. (0.3, 0.9)
			.. controls (0.9, 0.75) and (1, 0) .. (1.1, -0.4)
			.. controls (1.15, -0.6) and (1.05, -1.2) .. (0.8, -1.5) node[below] {$h$};
		\draw[fill, blue] (-1.1, 0.3) circle (0.08);
		\draw[fill, blue] (-1.2, -0.1) circle (0.08);
		\draw[fill, blue] (-1.3, -0.5) circle (0.08);
		\draw[fill, blue] (-1.2, -0.8) circle (0.08);
		\draw[fill, blue] (-0.8, -1.2) circle (0.08);
		\draw[fill, blue] (-0.3, -1.5) circle (0.08);
		\draw[fill, blue] (-0.6, 1) circle (0.08);
		\draw[fill, blue] (-0.9, 0.8) circle (0.08);
		\draw[fill, blue] (-0.95, 1.2) circle (0.08);
		\draw[fill, blue] (-0.2, 1.3) circle (0.08);
		\draw[fill, blue] (0.3, 1.1) circle (0.08);
		\draw[fill, blue] (0.7, 0.9) circle (0.08);
		\draw[fill, blue] (1.1, 0.5) circle (0.08);
		\draw[fill, blue] (1.3, 0.1) circle (0.08);
		\draw[fill, blue] (1.3, -0.4) circle (0.08);
		\draw[fill, blue] (1.25, -1.2) circle (0.08);
	\end{tikzpicture}
\end{center}
Ici $h$ convient aux données d'entraînement mais n'est toujours pas bon pour la généralisation.

\paragraph{Conjecture}
Plus l'ensemble $S$ sera grand, plus la fonction $h$ sera proche de $f$.

\paragraph{Malédiction de la dimensionnalité}
Quand le nombre de features augmente, le nombre $m$ d'exemples d'entraînement nécessaires pour généralisé de manière assez précise augmente exponentiellement.

\DEF{
	En statistiques, l'\textbf{overfitting} est le phénomène où le modèle obtenu est trop complexe. Il peu avoir trop de degrés de liberté par exemple. En revanche l'\textbf{underfitting} est lorsque le modèle n'arrive pas à trouver la tendance des données. 
}

\subs{Risque et fonction de perte}

\DEF{
	En théorie, on aime considéré la meilleurs hypothèse $h^* \in \Hyp$. En se donnant une \textbf{fonction de perte} $l : \Hyp \times \Z \rightarrow \R$ mesurant le degré d'accord entre $h(x)$ et $y$, le \textbf{vrai risque} ou \textbf{erreur de généralisation} $\trisk(h)$ est défini ainsi :
	$$ \trisk(h) = \E_{z \sim \dist} l(h, z) = \int_z f_\dist(z) l(h, z)$$
	$$ h^* = \argmin_{h \in \Hyp} \trisk(h) $$
	\vspace{-5mm}
}

Malheureusement, $\trisk(h)$ ne peut pas être calculé car $\dist$ est inconnu. On peut seulement calculé le \textbf{risque empirique} sur $S$. C'est à dire :
$$ \erisk(h) = \E_{z \sim S} l(h, z) = \frac{1}{m} \sum_{i = 1}^{m} l(h, z_i) $$
Ainsi le but de l'algorithme d'apprentissage supervisé est de trouver le modèle $\displaystyle h = \argmin_{h_i \in \Hyp} \erisk(h_i)$.

\exe
La fonction de perte la plus naturelle pour la classification binaire est le 0/1 loss.
$$ l_{0/1}(h, z) = \left\{ \begin{array}{ll}
	1 & \text{si } yh(x) < 0 \\
	0 & \text{sinon}
\end{array}
\right. $$
Ainsi $\mathcal{R}^{l_{0/1}}(h)$ est la proportion de mauvaises prédictions. \\
Malheureusement, à cause de la non-convexité et de la non-différentiabilité de cette fonction de perte, minimiser, ou même minimiser approximativement $\mathcal{\hat{R}}^{l_{0/1}}(h)$ est un problème NP-difficile.

\paragraph{Fonctions de perte usuelles} Pour cette raison, on utilise généralement les fonctions de perte convexes suivante :
\begin{itemize}
	\item La \textbf{perte exponentielle} (utilisée en boosting) : $l_{exp}(h, z) = e^{-yh(x)}$
	\item La \textbf{perte logistique} (utilisée en régression logistique) : $l_{log}(h, z) = \ln(1 + e^{-yh(x)})$
	\item La \textbf{perte charnière} (utilisée en SVM) : $l_{hinge}(h, z) = \max(0, 1 - yh(x))$
\end{itemize}
\begin{center}
	\begin{tikzpicture}[yscale=1.25, xscale=1.65, thick]
		\draw (-2, -0.5) node[below] {-2} -- (2, -0.5) node[below] {2};
		\draw (-2, -0.5) node[left] {-0.5} -- (-2, 3.5) node[left] {3.5};
		\draw (0, -0.5) node[] {\tiny |} node[below] {0};
		\draw (-2, 1.5) node[] {\tiny -} node[left] {1.5};
		\draw (-2, 1) node[left] {1} -- (0, 1) -- (0, 0) -- (2, 0);
		\draw[red] (-2, 3) -- (1, 0) -- (2, 0);
		\draw[domain=-1.25:2, smooth, variable=\x, blue] plot ({\x}, {exp(-\x)});
		\draw[domain=-2:2, smooth, variable=\x, greenTikz] plot ({\x}, {ln(1 + exp(-\x))});
		\draw (1.8, 3.3) -- (1.3, 3.3) node[left] {\footnotesize 0/1 loss};
		\draw[red] (1.8, 3) -- (1.3, 3) node[left] {\footnotesize hinge loss};
		\draw[greenTikz] (1.8, 2.7) -- (1.3, 2.7) node[left] {\footnotesize logistic loss};
		\draw[blue] (1.8, 2.4) -- (1.3, 2.4) node[left] {\footnotesize exponential loss};
	\end{tikzpicture}
\end{center}

\subs{Minimisation de risque régularisée}

Trop entraîner l'algorithme sur les données d'entraînement $S$ peut conduire à une mémorisation et à l'overfitting. Le modèle devient compliqué et on risque d'avoir une mauvaise généralisation. \\
Le principe du \textbf{rasoir d'Occam} est "le plus simple est le mieux". Pour appliquer ce principe, on essaye de minimiser les paramètres du modèle. \\
On va donc minimiser le \textbf{risque empirique régularisé} :
$$ \min_{h \in \Hyp} \erisk(h) + \lambda \| h \| $$
On pénalise alors les hypothèses avec une forte norme.

\DEF{
	La norme $l_p$ d'un vecteur $\theta$ d'un espace à $d$ dimensions est défini comme suit :
	$$ \| \theta \|_p = \left( \sum_{i = 1}^d |\theta_i|^p \right)^{\frac{1}{p}} $$
	\vspace{-5mm}
}

\begin{center}
	\begin{tikzpicture}[thick, >={latex}, scale=0.8]
		\draw[->] (0, 0) -- (2, 0);
		\draw[->] (1, -1) node[below] {$p=0$} -- (1, 1);
		\draw[red, very thick] (0.3, 0) -- (1.7, 0);
		\draw[red, very thick] (1, -0.7) -- (1, 0.7);
		
		\draw[->] (3, 0) -- (5, 0);
		\draw[->] (4, -1) node[below] {$p=0.3$} -- (4, 1);
		\draw[domain=-1:1, smooth, variable=\x, red, very thick]
			plot ({0.8*\x+4}, {0.8 * max(0.01, 1 - abs(\x)^0.3)^(1/0.3)});
			\draw[domain=-1:1, smooth, variable=\x, red, very thick]
			plot ({0.8*\x+4}, {-0.8 * max(0.01, 1 - abs(\x)^0.3)^(1/0.3)});
			
		\draw[->] (6, 0) -- (8, 0);
		\draw[->] (7, -1) node[below] {$p=0.5$} -- (7, 1);
		\draw[domain=-1:1, smooth, variable=\x, red, very thick]
			plot ({0.8*\x+7}, {0.8 * max(0.01, 1 - abs(\x)^0.5)^(1/0.5)});
		\draw[domain=-1:1, smooth, variable=\x, red, very thick]
			plot ({0.8*\x+7}, {-0.8 * max(0.01, 1 - abs(\x)^0.5)^(1/0.5)});
		
		\draw[->] (9, 0) -- (11, 0);
		\draw[->] (10, -1) node[below] {$p=1$} -- (10, 1);
		\draw[red, very thick] (9.2, 0) -- (10, 0.8) -- (10.8, 0) -- (10, -0.8) -- (9.2, 0);
		
		\draw[->] (12, 0) -- (14, 0);
		\draw[->] (13, -1) node[below] {$p=1.5$} -- (13, 1);
		\draw[domain=-1:1, smooth, variable=\x, red, very thick]
			plot ({0.8*\x+13}, {0.8 * max(0.01, 1 - abs(\x)^1.5)^(1/1.5)});
		\draw[domain=-1:1, smooth, variable=\x, red, very thick]
			plot ({0.8*\x+13}, {-0.8 * max(0.01, 1 - abs(\x)^1.5)^(1/1.5)});
		
		\draw[->] (15, 0) -- (17, 0);
		\draw[->] (16, -1) node[below] {$p=2$} -- (16, 1);
		\draw[red, very thick] (16, 0) circle (0.8);
		
		\draw[->] (18, 0) -- (20, 0);
		\draw[->] (19, -1) node[below] {$p=inf$} -- (19, 1);
		\draw[red, very thick] (18.2, 0.8) -- (19.8, 0.8) -- (19.8, -0.8) -- (18.2, -0.8) -- (18.2, 0.8);
	\end{tikzpicture}
\end{center}

La norme $l_2$ est utilisée pour réduire les risques d'overfitting en réduisant les plus grandes valeurs du modèle. La norme $l_1$, elle permet d'obtenir des modèles sparses, c'est à dire avec peu de features.

\exe
Considérons le problème suivant :
$$ \min_{\theta \in \R^d} \frac{1}{2} \theta^\trans \theta - \theta^\trans x + \lambda \| \theta \|_2^2 $$
Si $\lambda = 0$, alors :
$$ \dfrac{\partial \frac{1}{2} \theta^\trans \theta - \theta^\trans x}{\partial \theta_j} = 0 \Rightarrow \theta_j - x_j = 0 \Rightarrow \fbox{$\theta_j = x_j$} $$
Si $\lambda \neq 0$, alors :
$$ \dfrac{\partial \frac{1}{2} \theta^\trans \theta - \theta^\trans x  + \lambda \| \theta \|_2^2}{\partial \theta_j} = 0 \Rightarrow \theta_j - x_j +2\lambda \theta_j = 0 \Rightarrow \fbox{$\theta_j = \dfrac{x_j}{1 + 2\lambda}$} $$
\begin{center}
	\begin{tikzpicture}[>={latex}, thick]
	\draw[->] (-1, 0) -- (5, 0);
	\draw[->] (0, -1) -- (0, 3.5);
	\draw (3, 0) node {\tiny |} node[below] {3};
	\draw (0, 2) node {\tiny -} node[left] {2};
	\draw[fill] (3, 2) circle (0.05) node[below] {$x$};
	\draw[fill=greenTikz, fill opacity=0.5, very thick] (3, 2) circle (1.4^0.5);
	\draw[very thick] (3, 2) circle (1) circle (0.6^0.5) circle (0.2^0.5);
	\node[color=red] at (1, -0.6) {$\lambda = 0$};
	
	\draw[->] (7, 0) -- (13, 0);
	\draw[->] (8, -1) -- (8, 3.5);
	\draw (11, 0) node {\tiny |} node[below] {3};
	\draw (8, 2) node {\tiny -} node[left] {2};
	\draw[fill] (11, 2) circle (0.05) node[below] {$x$};
	\draw[fill=greenTikz, fill opacity=0.5, very thick] (9, 0.67) circle (0.47^0.5);
	\draw[very thick] (9, 0.67) circle (0.33^0.5) circle (0.2^0.5) circle (0.07^0.5);
	\node[color=red] at (9, -0.6) {$\lambda = 1$};
	\end{tikzpicture}
\end{center}

\exe
Maintenant on peut prendre la norme $l_1$ pour constater qu'elle engendre bien de la sparsité.
$$ \min_{\theta \in \R^d} \frac{1}{2} \theta^\trans \theta - \theta^\trans x + \lambda \| \theta \|_1 $$
Si $\lambda = 0$, on a vu que $\theta^* = x$. \\
En revanche si $\lambda > 0$, on considère la dérivée partielle à $\theta_j = 0^+$, et à $\theta_j = 0^-$ :
$$ g_+^j = \lambda - x_j \qquad g_-^j = - \lambda - x_j $$
Or $\theta_j^* = 0$ si et seulement si $g_+^j \geqslant 0$ et $g_-^j \leqslant 0$. C'est à dire si $x_j \geqslant \lambda$ et $x_j \leqslant -\lambda$. \\
Donc si $|x_j| \leqslant \lambda$ alors $\theta_j^* = 0$.
\begin{center}
	\begin{tikzpicture}[>={latex}, thick, scale=0.8]
	\draw[->] (-1, 0) -- (5, 0);
	\draw[->] (0, -1) -- (0, 3.5);
	\draw (3, 0) node {\tiny |} node[below] {3};
	\draw (0, 2) node {\tiny -} node[left] {2};
	\node[color=red] at (1, -0.6) {$\lambda = 0$};
	\draw[fill] (3, 2) circle (0.05) node[below] {$x$};
	\draw[fill=greenTikz, fill opacity=0.5, very thick] (3, 2) circle (5^0.5);
	\draw[very thick] (3, 2) circle (3^0.5) circle (1);
	
	\draw[->] (7, 0) -- (13, 0);
	\draw[->] (8, -1) -- (8, 3.5);
	\draw (11, 0) node {\tiny |} node[below] {3};
	\draw (8, 2) node {\tiny -} node[left] {2};
	\draw[fill] (11, 2) circle (0.05) node[below] {$x$};
	\draw[fill, red] (9, 0) circle (0.05) node[above] {$\theta^*$};
	\node[color=red] at (12.4, 3) {$\lambda = 2$};
	\node[color=red] at (12.4, 2.5) {$\theta^*$ est sparse};
	\draw[very thick, fill=greenTikz, fill opacity=0.5] (11.24, 0) arc (0:116.6:2.24);
	\draw[very thick, fill=greenTikz, fill opacity=0.5] (8, 2) arc (158:180:5.39);
	\draw[very thick, fill=greenTikz, fill opacity=0.5] (7.61, 0) arc (217:222.4:6.71);
	\draw[very thick, fill=greenTikz, fill opacity=0.5] (8, -0.47) arc (257.4:299.1:4.58);
	\draw[very thick] (10, 0) arc(0:180:1);
	\draw[very thick] (8, 0) arc(-104:-76:4.12);
	\draw[very thick] (10.73, 0) arc(0:125:3^0.5);
	\draw[very thick] (7.8, 0) arc(180:164:27^0.5);
	\draw[very thick] (7.8, 0) arc(217.6:220.5:43^0.5);
	\draw[very thick] (10.73, 0) arc(-66.6:-103:19^0.5);
	\fill[greenTikz, opacity=0.5] (11.24, 0) -- (8, 2) -- (7.61, 0) -- (8, -0.47);
	\end{tikzpicture}
\end{center}

\paragraph{Supprimer des groupes de features}
Voici des normes qui permettent de supprimer les features en groupe :
\begin{center}
	\includegraphics[scale=0.5]{group_sparse.png}
\end{center}
On considère $\{ \mathcal{G}_{k = 1}^K \}$ une partition de $\{ 1, \dots, d \}$. On peur alors définir les normes suivantes :
$$ \| \theta \|_{group} = \sum_{g \in \mathcal{G}} \left( \sum_{j \in g} \theta_j^2 \right)^{\frac{1}{2}} $$
$$ \| \theta \|_{coop} = \sum_{g \in \mathcal{G}} \left[ \left( \sum_{j \in g} [\theta_j]_+^2 \right)^{\frac{1}{2}} + \left( \sum_{j \in g} [\theta_j]_-^2 \right)^{\frac{1}{2}} \right] $$


\subs{Contrepartie Biais/Variance}

D'où vient l'erreur de $h \in \Hyp$ ?
\begin{itemize}
	\item Du \textbf{biais inductif}. Rien ne garantie l'égalité entre l'espace cible des concepts $\mathcal{F}$ et la classe d'hypothèse que l'on a choisi $\Hyp$.
	\item De la \textbf{variance}. Comme l'ensemble d'entraînement est fini et choisi aléatoirement selon $\dist$, l'algorithme d'apprentissage ne retourne pas l'hypothèse optimale $h^*$ de $\Hyp$.
\end{itemize}

\begin{center}
	\begin{tikzpicture}[thick]
		\draw (0, 0.5) -- (4, 0.5) -- (4, 2) -- node[above] {$\Hyp$} (0, 2) -- (0, 0.5);
		\node at (5.5, 0.5) {$\mathcal{F}$};
		\draw[fill] (0.5, 1) circle (0.05) node[above] {$h$}
			-- node[below, sloped] {\footnotesize erreur totale} (3.7, -1)
				circle (0.05) node[right] {$f$}
			-- node[above, sloped] {\footnotesize biais} (2.5, 1)
				circle (0.05) node[above] {$h^*$}
			-- node[above] {\footnotesize Variance} (0.5, 1);
	\end{tikzpicture}
\end{center}
$$ \trisk(h) \leqslant \text{Biais} + \text{Variance} $$
$$ \trisk(h) \leqslant \text{Biais inévitable} + \text{Biais évitable} + \text{Variance} $$
$$ \trisk(h) \leqslant {\color{red}\text{Erreur de Bayes}} + {\color{blue}\text{Biais évitable}} + {\color{blue}\text{Variance}} $$

\DEF{
	L'\textbf{erreur de Bayes} $\epsilon_B$ est le plus petit taux d'erreur pour une hypothèse $h$ :
	$$ \epsilon_B = \sum_i \int_{(x, y) \in R_i \times \bar{C_i}} P(C_i | x) p(x) dx $$
	Où $x$ est une instance avec $y$ pour étiquette et $R_i$ est la région que la fonction de classification $h$ classifie comme $C_i$.
}
\begin{center}
	C'est un $\ll$ sept $\gg$ ou un $\ll$ un $\gg$ ? \\
	\includegraphics[scale=0.4]{one_seven.png}
\end{center}

\paragraph{Variance}
$h$ va converger vers $h^*$ si on augmente le nombre d'exemples $m$.
\begin{center}
	\begin{tikzpicture}[thick, scale=0.9]
		\draw[ultra thick, blue, opacity=0.8] (0, -2.5) -- (0, 2.5);
		\draw[ultra thick, blue, opacity=0.8] (-1.6, -2.5) -- (0.25, 2.5);
		\node[below] at (-1.6, -2.5) {$h$};
		\node[below] at (0, -2.5) {$h^*$};
		\draw[<->, red] (-0.3, -2.8) -- node[black, above] {?} (-1.4, -2.8);
		\draw[fill, red] (0.1, -2) circle (0.07);
		\draw[fill, red] (-0.6, -1) circle (0.07);
		\draw[fill, red] (0.3, 0.5) circle (0.07);
		\draw[fill, red] (0.5, 2) circle (0.07);
		\draw[fill, red, opacity=0.3] (-0.5, 0) circle (0.07);
		\draw[fill, red, opacity=0.3] (0.3243, 0.9859) circle (0.07);
		\draw[fill, red, opacity=0.3] (-0.08914, 0.978) circle (0.07);
		\draw[fill, red, opacity=0.3] (2.427, 0.7918) circle (0.07);
		\draw[fill, red, opacity=0.3] (1.4609, 1.212) circle (0.07);
		\draw[fill, red, opacity=0.3] (1.3548, 0.6159) circle (0.07);
		\draw[fill, red, opacity=0.3] (1.403, 0.351) circle (0.07);
		\draw[fill, red, opacity=0.3] (-0.351, 1.57183) circle (0.07);
		\draw[fill, red, opacity=0.3] (0.10869, 1.876) circle (0.07);
		\draw[fill, red, opacity=0.3] (-0.13232, 1.62) circle (0.07);
		\draw[fill, red, opacity=0.3] (0.048154, 0.0303) circle (0.07);
		\draw[fill, red, opacity=0.3] (0.0214, -0.861) circle (0.07);
		\draw[fill, red, opacity=0.3] (-0.10329, -1.902) circle (0.07);
		\draw[fill, red, opacity=0.3] (-0.049, -0.0497) circle (0.07);
		\draw[fill, red, opacity=0.3] (1.3507, -1.7576) circle (0.07);
		\draw[fill, red, opacity=0.3] (-0.4912, -0.3749) circle (0.07);
		\draw[fill, red, opacity=0.3] (1.0138, -0.184) circle (0.07);
		\draw[fill, red, opacity=0.3] (2.0108, 0.5766) circle (0.07);
		\draw[fill, red, opacity=0.3] (2.0224, 1.0361) circle (0.07);
		\draw[fill, red, opacity=0.3] (0.0751, 1.7442) circle (0.07);
		\draw[fill, red, opacity=0.3] (2.0863, 1.7777) circle (0.07);
		\draw[fill, red, opacity=0.3] (-0.0409, -0.1897) circle (0.07);
		\draw[fill, red, opacity=0.3] (0.2889, -0.0546) circle (0.07);
		\draw[fill, red, opacity=0.3] (2.4079, -0.1523) circle (0.07);
		\draw[fill, red, opacity=0.3] (1.8439, 1.2179) circle (0.07);
		
		\draw[fill, blue] (-0.8, 1.5) circle (0.07);
		\draw[fill, blue] (-1.2, 0.9) circle (0.07);
		\draw[fill, blue] (-1.6, -0.8) circle (0.07);
		\draw[fill, blue] (-1.6, -1.7) circle (0.07);
		\draw[fill, blue, opacity=0.3] (-1.9025, 0.0568) circle (0.07);
		\draw[fill, blue, opacity=0.3] (-0.2239, -0.3909) circle (0.07);
		\draw[fill, blue, opacity=0.3] (-0.6662, 0.0906) circle (0.07);
		\draw[fill, blue, opacity=0.3] (0.4667, 0.1391) circle (0.07);
		\draw[fill, blue, opacity=0.3] (-0.0517, -1.9698) circle (0.07);
		\draw[fill, blue, opacity=0.3] (-1.1208, -0.8846) circle (0.07);
		\draw[fill, blue, opacity=0.3] (0.1495, -0.2879) circle (0.07);
		\draw[fill, blue, opacity=0.3] (-2.4247, 0.4716) circle (0.07);
		\draw[fill, blue, opacity=0.3] (-1.9027, -1.2081) circle (0.07);
		\draw[fill, blue, opacity=0.3] (-1.4246, 1.5652) circle (0.07);
		\draw[fill, blue, opacity=0.3] (-1.729, 1.9974) circle (0.07);
		\draw[fill, blue, opacity=0.3] (-0.5392, 1.2422) circle (0.07);
		\draw[fill, blue, opacity=0.3] (0.3168, 0.8305) circle (0.07);
		\draw[fill, blue, opacity=0.3] (-0.2799, 0.1071) circle (0.07);
		\draw[fill, blue, opacity=0.3] (-1.5449, 0.0752) circle (0.07);
		\draw[fill, blue, opacity=0.3] (-1.8949, -0.0877) circle (0.07);
		\draw[fill, blue, opacity=0.3] (-0.9253, -0.423) circle (0.07);
		\draw[fill, blue, opacity=0.3] (0.279, -1.1842) circle (0.07);
		\draw[fill, blue, opacity=0.3] (-0.152, 0.5651) circle (0.07);
		\draw[fill, blue, opacity=0.3] (-0.8953, -1.1821) circle (0.07);
		\draw[fill, blue, opacity=0.3] (-0.3335, 1.352) circle (0.07);
		\draw[fill, blue, opacity=0.3] (-0.4852, -1.6634) circle (0.07);
	\end{tikzpicture}
\end{center}

\paragraph{Biais évitable}
La distance entre l'espace $\Hyp$ et $f$ va diminuer si on augmente l'expressivité de $h$ et notamment en augmentant la dimension.

\paragraph{Conclusion}
Malheureusement, augmenter la dimension augmente aussi la variance. Il faut donc trouver un bon compromis sur la dimension pour réduire le biais sans trop augmenter la variance.
\begin{center}
	\begin{tikzpicture}[thick, >={latex}]
		\draw[->] (0, 0) -- (5, 0) node[below] {dimension de $\Hyp$};
		\draw[->] (0, 0) -- (0, 3.5);
		\draw[domain=0:4.2, smooth, variable=\x, blue]
			plot ({\x}, {3 - \x * (0.33 + 0.05 * \x)})
			node[right] {\footnotesize Biais};
		\draw[domain=0:4.2, smooth, variable=\x, blue]
			plot ({\x}, {0.1 + 0.08 * \x + 0.42 * exp(1.44 * \x - 4.2)})
			node[right] {\footnotesize Variance};
		\draw[domain=0:4, smooth, variable=\x, red]
			plot ({\x}, {3.1 - \x * (0.25 + 0.05 * \x) + 0.42 * exp(1.44 * \x - 4.2)});
		\draw[red] (2.85, 0.3) -- (2.85, 2.7) node[above] {\footnotesize $\trisk(h)^{min}$};
	\end{tikzpicture}
\end{center} 

\subs{Bornes de généralisation}

\paragraph{But}
Notre objectif est d'obtenir des bornes \textbf{PAC (Probably Approximately Correct)} de la forme suivante : Avec probabilité $1 - \delta$
$$ \begin{array}{lll}
	\trisk(h) & \leqslant & \erisk(h) + \gamma \\
	 & \leqslant & \erisk(h^*) + 2 \gamma \qquad \text{(car } h = \argmin_{h_i \in \Hyp} \erisk(h_i)) \\
	 & \leqslant & (\trisk(h^*) + \gamma) + \gamma \\
	 & \leqslant & \trisk(h^*) + 2 \gamma
\end{array} $$

La théorie de la convergence uniforme nous donne des garanties pour les hypothèses $h \in \Hyp$. La question que l'on se pose est : Sous quelle conditions (sur le nombre minimum d'exemples d'entraînement requis) peut-on obtenir des bornes PAC valides ? \\
On va considérer deux situations. La première est celle où $|\Hyp| = k$ est fini. La seconde est celle où $\Hyp$ est infini.

\subsubs{Convergence uniforme - Cas fini}

On commence par rappeler le lemme suivant: \vspace{3mm}
\PROP[ (Inégalité de Hoeffding)]{
	Soit $Z_1, \dots, Z_m$ $m$ variables i.i.d suivant des loi de Bernoulli d'espérance $\phi$. On pose la variable $\hat{\phi} = \frac{1}{m} \sum_{i = 1}^m Z_i$ et on considère $\gamma > 0$. Alors : \vspace{-2mm}
	$$ \Pp(|\hat{\phi} - \phi| > \gamma) \leqslant 2 \exp(-2 \gamma^2 m) $$
	\vspace{-9mm}
}
\vspace{2mm}

On considère alors l'espace $\Hyp = \{ h_1, \dots, h_k \}$. L'inégalité de Hoeffding peut être appliqué à $\trisk(h)$ et $\erisk(h)$ avec $l(h, z_i)$ qui est une loi de Bernoulli d'espérance $\trisk(h)$. On pose donc $A_j$ l'événement $| \trisk(h) - \erisk(h) | \geqslant \gamma$. Avec l'inégalité de Hoeffding, on a : $\Pp(A_j) \leqslant 2 e^{-2 \gamma^2 m}$. Et cela donne :
$$ \begin{array}{lll}
	\Pp(\sup_{h \in \Hyp} | \trisk(h) - \erisk(h) | \geqslant \gamma )
	 & = & \Pp(A_1 \cup \dots \cup A_k) \\
	 & \leqslant & \sum_j \Pp(A_j) \\
	 & \leqslant & \sum_j 2 e^{-2 \gamma^2 m} \\
	 & \leqslant & 2k e^{-2 \gamma^2 m}
\end{array} $$

\paragraph{Borne sur $m$}
Avec l'inégalité précédente on peut essayer de trouver la valeur minimale de $m$ pour que la probabilité soit au plus $\delta$ :
$$ \begin{array}{lll}
	2k e^{-2 \gamma^2 m} \leqslant \delta
	 & \Leftrightarrow & e^{2 \gamma^2 m} \geqslant \dfrac{2k}{\delta} \\
	 & \Leftrightarrow & 2 \gamma^2 m \geqslant \ln \left( \dfrac{2k}{\delta} \right) \\
	 & \Leftrightarrow & m \geqslant \dfrac{1}{2 \gamma^2} \ln \left( \dfrac{2k}{\delta} \right)
\end{array} $$
Donc si $m \geqslant \dfrac{1}{2 \gamma^2} \ln \left( \dfrac{2k}{\delta} \right)$ alors avec probabilité $1 - \delta$, on a :
$$ \trisk(h) \leqslant \erisk(h) + \gamma $$
Mais généralement $m$ est fixé.

\paragraph{Borne sur $\gamma$}
Pour un $m$ fixé et une probabilité $\delta$ fixée, on obtient :
$$ \gamma = \sqrt{\dfrac{1}{2m} \ln \left( \dfrac{2k}{\delta} \right)} $$

\PROP[ (Borne de généralisation dans le cas fini)] {
	Avec probabilité $1 - \delta$, on a pour tout $h$ dans $\Hyp$ :
	$$ \trisk(h) \leqslant \erisk(h) + \sqrt{\dfrac{1}{2m} \ln \left( \dfrac{2k}{\delta} \right)} $$
	\vspace{-5mm}
}

\subsubs{Convergence uniforme - Cas infini}

On introduit la dimension VC (pour Vapnik-Chervonenkis) qui est une mesure de la capacité (ou complexité) de la classe des hypothèses $\Hyp$.

\DEF{
	Un ensemble de point $S$ est \textbf{pulvérisé} par $\Hyp$ si pour tout sous-ensembles $A$ de $S$, il existe une hypothèse $h \in \Hyp$ qui ne fait pas d'erreur sur $A$. Autrement dit $S$ est pulvérisé par $\Hyp$ si les éléments de $\Hyp$ permettent d'obtenir les $2^{|S|}$ dichotomies de $S$. \\
	La \textbf{dimension VC} $d_\Hyp$ d'une classe d'hypothèses $\Hyp$ est défini comme le plus grand cardinal de points que $\Hyp$ peut pulvériser.
}

\begin{center}
	\begin{tikzpicture}[thick, >={latex}]
		\draw (0, 5.5) circle (0.12);
		\draw (1, 5.5) circle (0.12);
		\draw (1, 4.5) circle (0.12);
		\draw (4, 5.5) circle (0.12);
		\draw (10, 5.5) circle (0.12);
		\draw (10, 4.5) circle (0.12);
		\draw (1, 2.5) circle (0.12);
		\draw (3, 3.5) circle (0.12);
		\draw (6, 3.5) circle (0.12);
		\draw (7, 3.5) circle (0.12);
		\draw (9, 3.5) circle (0.12);
		\draw (10, 2.5) circle (0.12);
		
		\draw[fill] (3, 5.5) circle (0.12);
		\draw[fill] (4, 4.5) circle (0.12);
		\draw[fill] (6, 5.5) circle (0.12);
		\draw[fill] (7, 5.5) circle (0.12);
		\draw[fill] (7, 4.5) circle (0.12);
		\draw[fill] (9, 5.5) circle (0.12);
		\draw[fill] (0, 3.5) circle (0.12);
		\draw[fill] (1, 3.5) circle (0.12);
		\draw[fill] (4, 3.5) circle (0.12);
		\draw[fill] (4, 2.5) circle (0.12);
		\draw[fill] (7, 2.5) circle (0.12);
		\draw[fill] (10, 3.5) circle (0.12);
		
		\draw (-1, 4) -- (11, 4);
		\draw (2, 2.2) -- (2, 5.8);
		\draw (5, 2.2) -- (5, 5.8);
		\draw (8, 2.2) -- (8, 5.8);
		
		\draw (-0.5, 5.7) -- (1.2, 4);
		\draw[->] (0.35, 4.85) -- (0.05, 4.55);
		\draw (3.3, 5.7) -- (4.2, 4.8);
		\draw[->] (3.75, 5.25) -- (3.45, 4.95);
		\draw (5.5, 5.7) -- (7.2, 4);
		\draw[->] (6.35, 4.85) -- (6.65, 5.15);
		\draw (9.5, 4.2) -- (9.5, 5.7);
		\draw[->] (9.5, 5) -- (9.05, 5);
		\draw (-0.3, 3) -- (1.3, 3); 
		\draw[->] (0.5, 3) -- (0.5, 3.45);
		\draw (3.5, 2.2) -- (3.5, 3.8);
		\draw[->] (3.5, 3) -- (3.95, 3);
		\draw (5.7, 3) -- (7.3, 3); 
		\draw[->] (6.5, 3) -- (6.5, 2.55);
		\draw (9.2, 3.7) -- (10.2, 2.7);
		\draw[->] (9.7, 3.2) -- (9.9, 3.4);
	\end{tikzpicture}
\end{center}

Avec $d_\Hyp$ on peut obtenir une borne pour $\trisk(h)$.

\PROP[ (Borne de généralisation dans le cas infini)] {
	Avec probabilité $1 - \delta$, on a pour tout $h$ dans $\Hyp$ :
	$$ \trisk(h) \leqslant \erisk(h) + \sqrt{\dfrac{d_\Hyp \left( \ln \frac{2 m}{d_\Hyp} + 1 \right) + ln \frac{4}{\delta}}{m}} $$
	\vspace{-5mm}
}

Au lieu d'utiliser la dimension VC, on peut aussi utiliser la complexité de Rademacher.

\DEF{
	La \textbf{complexité empirique de Rademacher} de $\Hyp$ est :
	$$ Rad_m(\Hyp, S) = \E \left( \sup_{h \in \Hyp} \left| \frac{1}{m} \sum_{i = 1}^m \sigma_i h(z_i) \right| \right) $$
	Où $\sigma_1, \dots, \sigma_m$ sont $m$ variables de Rademacher i.i.d avec $\Pp(\sigma_i = 1) = \Pp(\sigma_i = -1) = \frac{1}{2}$.
}

\PROP[ (Borne de convergence uniforme avec la complexité de Rademacher)] {
	Avec probabilité $1 - \delta$, on a pour tout $h$ dans $\Hyp$ : \vspace{-3mm}
	$$ \trisk(h) \leqslant \erisk(h) + 2 Rad_m(\Hyp, S) + \sqrt{\dfrac{4}{m} ln \left( \dfrac{2}{\delta} \right)} $$
	\vspace{-5mm}
}

\subs{Choix du modèle}